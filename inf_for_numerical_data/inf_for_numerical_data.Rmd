---
title: 'Inference for numerical data'
output:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
  pdf_document: default
---

```{r opts, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

## North Carolina births

In 2004, the state of North Carolina released a large data set containing 
information on births recorded in this state. This data set is useful to 
researchers studying the relation between habits and practices of expectant 
mothers and the birth of their children. We will work with a random sample of 
observations from this data set.

## Exploratory analysis

Load the `nc` data set into our workspace.

```{r load-data, message = FALSE}
library(mosaic)
library(oilabs)
data(nc)
head(nc)
```

We have observations on 13 different variables, some categorical and some 
numerical. You can read more about each one in the help file.

```{r nc_help}
?nc
```

1.  What are the cases in this data set? How many cases are there in our sample?

As a first step in the analysis, we should consider numerical summaries of the 
data. This can be done using the `summary` command:

```{r summary}
summary(nc)
```

As you review the variable summaries, consider which variables are categorical 
and which are numerical. For numerical variables, are there outliers? If you 
aren't sure or want to take a closer look at the data, make a plot.

Consider the possible relationship between a mother's smoking habit and the 
weight of her baby. Plotting the data is a useful first step because it helps 
us quickly visualize trends, identify strong associations, and develop research
questions.

2.  Make a side-by-side boxplot of `habit` and `weight`. What does the plot 
highlight about the relationship between these two variables?

The box plots show how the medians of the two distributions compare, but we can
also compare the means of the distributions. There are several ways we could do this. 
One it to use the standard `mean` function, 
```{r mosaicmean}
mean(~weight|habit, data=nc)
```

We could also build a `dplyr` chain, to take
the `nc` data, group it by `habit`, then summarize each group's `weight` by taking
the mean.

```{r by-means}
nc %>%
  group_by(habit) %>%
  summarize(mean(weight))
```

The results from these two pieces of code should be the same. However, notice what
happens with NA values in the first version. 

Either way, we can say that there is an observed difference between the means, but 
we want to know if this difference is statistically. In order to answer this 
question we will conduct a hypothesis test.

## Inference

3.  Write the hypotheses for testing if the average weights of babies born to 
smoking and non-smoking mothers are different.

4.  What is our test statistic? What distribution would you expect it to follow?

5.  Check if the conditions necessary for inference are satisfied. Note that 
you will need to obtain sample sizes to check the conditions. You can compute 
the group size using the same dplyr chain above but replacing summarizing each group
with `n()` instead of `mean(weight)`.

Now we can compute a T score to complete our hypothesis test. To do this, we need a few pieces of information. First, we need point estimates for our means. We're also going to need the sample standard deviation and the number of observations in each group, so we might as well calculate those statistics at the same time. 

```{r inf-weight-habit-ht, tidy=FALSE}
smoke_stats <- nc %>%
  group_by(habit) %>%
  filter(habit != "NA") %>%
  summarize(mean = mean(weight), sd = sd(weight), n = n())

smoke_stats
```

Once we have that information from our data, we can start working on our standard error. Recall that the standard error for a difference of two (unpooled) means is 

$$SE = \sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_1}} \approx \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_1}}$$

So, we want to find the $s^2/n$ for each of our groups, as well as the point estimate of the difference of means. 
```{r}
smoke_stats <- smoke_stats %>%
  mutate(sd2s = sd^2/n, diff = mean - lag(mean))

inference <- smoke_stats %>%
  select(diff)%>%
  slice(2)
```
From there, we can complete our SE calculation. 
```{r computing-se}
inference <- inference %>%
  mutate(se = sqrt(sum(~sd2s, data=smoke_stats)))
```
Of course, once we have our point estimate and standard error, it is simple to compute our T statistic. 
```{r t-stat}
inference <- inference %>%
  mutate(t = (diff-0)/se)

inference
```

6. Once you have a T statistic, how do you use it to find a p-value? Name at least one method. What information do you need to find the value?

One method is to use the `pt()` function. 

7.  Instead of finding a p-value, construct and record a confidence 
interval for the difference between the weights of babies born to smoking and 
non-smoking mothers. 


* * *

## On your own

For the following inferential exercises, be sure to assess the conditions for
inference.

-   Calculate a 95% confidence interval for the average length of pregnancies 
(`weeks`) and interpret it in context. 

-   Conduct a hypothesis test evaluating whether the average weight gained by 
younger mothers is different from the average weight gained by mature mothers.
Be sure to state hypotheses.

-   Now, a non-inference task: Determine the age cutoff that was used to separate
younger and mature mothers. Use a method of your choice, and explain how your method works.

-   Pick a pair of numerical and categorical variables and come up with a 
research question evaluating the relationship between these variables. 
Formulate the question in a way that it can be answered using a hypothesis test
and/or a confidence interval. Please outline the hypotheses, find a p-value or confidence interval, report the statistical results, and also provide an explanation in 
plain language.

<div id="license">
This is a product of OpenIntro that is released under a [Creative Commons 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0).
This lab was adapted for OpenIntro by Mine &Ccedil;etinkaya-Rundel from a lab 
written by the faculty and TAs of UCLA Statistics.
</div>